{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rinnakk/japanese-stable-diffusion/blob/master/scripts/img2img.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TitleTop"
      },
      "source": [
        "# Image2Image pipeline for Japanese Stable Diffusion\n",
        "\n",
        "Japanese Stable Diffusion is a Japanese-specific latent text-to-image diffusion model.\n",
        "\n",
        "This Colab notebook shows how to use Japanese Stable Diffusion using diffusers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LicenseTop"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "License"
      },
      "source": [
        "[The CreativeML OpenRAIL M license](LICENSE)  is an [Open RAIL M license](https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses), adapted from the work that [BigScience](https://bigscience.huggingface.co/) and [the RAIL Initiative](https://www.licenses.ai/) are jointly carrying in the area of responsible AI licensing. See also [the article about the BLOOM Open RAIL license](https://bigscience.huggingface.co/blog/the-bigscience-rail-license) on which our license is based."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SetupTop"
      },
      "source": [
        "## 1. Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "CheckGPU"
      },
      "source": [
        "#@title 1.1 Check GPU Status\n",
        "import subprocess\n",
        "try:\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InstallTop"
      },
      "source": [
        "## 2. Install packages and define necessary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Install"
      },
      "source": [
        "try:\n",
        "    from japanese_stable_diffusion import JapaneseStableDiffusionImg2ImgPipeline\n",
        "except:\n",
        "    res = subprocess.run(['pip', 'install', 'git+https://github.com/rinnakk/japanese-stable-diffusion'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "    from japanese_stable_diffusion import JapaneseStableDiffusionImg2ImgPipeline\n",
        "import io, requests\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import DDIMScheduler\n",
        "from PIL import Image\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "def make_grid_from_pils(pil_images):\n",
        "    w, h = pil_images[0].size\n",
        "    grid_img = Image.new(\"RGB\", ((len(pil_images)) * w, h))\n",
        "    for idx, image in enumerate(pil_images):\n",
        "        grid_img.paste(image, (idx * w, 0))\n",
        "    return grid_img\n",
        "\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoadTop"
      },
      "source": [
        "## 2. Load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoginInfo"
      },
      "source": [
        "You need to accept the model license before downloading or using the weights. So, you'll need to visit its card, read the license and tick the checkbox if you agree.\n",
        "\n",
        "You have to be a registered user in \ud83e\udd17 Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Login"
      },
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Load"
      },
      "source": [
        "model_id = \"rinna/japanese-stable-diffusion\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipe = JapaneseStableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ").to(device)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SettingTop"
      },
      "source": [
        "# 3. Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Setting"
      },
      "source": [
        "#@markdown ###**Inference Setting:**\n",
        "prompt = '\u732b\u306e\u8096\u50cf\u753b \u6cb9\u7d75' #@param{type: 'string'}\n",
        "# initial image. This can be a url or a path in colab\n",
        "init_image = \"https://cdn.pixabay.com/photo/2015/11/16/14/43/cat-1045782_960_720.jpg\" #@param{type: 'string'}\n",
        "# the number of output images. If you encounter Out Of Memory error, decrease this number.\n",
        "n_samples = 1 #@param{type: 'integer'}\n",
        "# `classifier-free guidance scale` adjusts how much the image will be like your prompt. Higher values keep your image closer to your prompt.\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "# strength for noising. 1.0 means text-to-image without init_image.\n",
        "strength = 0.75 #@param {type:\"number\"}\n",
        "# How many steps to spend generating (diffusing) your image.\n",
        "steps = 50 #@param{type: 'integer'}\n",
        "# The width of the generated image.\n",
        "width = 512 #@param{type: 'integer'}\n",
        "# The height of the generated image.\n",
        "height = 512 #@param{type: 'integer'}\n",
        "# The seed used to generate your image. Enable to manually set a seed.\n",
        "seed = 'random' #@param{type: 'string'}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RunTop"
      },
      "source": [
        "# 4. Run!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CheckImage"
      },
      "source": [
        "init_img = Image.open(fetch(init_image)).convert(\"RGB\").resize((width, height))\n",
        "init_img"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoTheRun"
      },
      "source": [
        "#@title Do the Run!\n",
        "if seed == \"random\":\n",
        "    generator = None\n",
        "else:\n",
        "    generator = torch.Generator(device=device).manual_seed(int(seed))\n",
        "\n",
        "\n",
        "with autocast(device):\n",
        "    images = pipe(\n",
        "        prompt=[prompt] * n_samples,\n",
        "        init_image=init_img,\n",
        "        strength=strength,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=steps,\n",
        "        generator=generator\n",
        "    )[\"sample\"]\n",
        "\n",
        "\n",
        "grid_img = make_grid_from_pils(images)\n",
        "grid_img.save('output.png')\n",
        "display.clear_output(wait=True)\n",
        "display.display(display.Image('output.png'))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RunGradioTop"
      },
      "source": [
        "# 5. Run with Gradio Demo!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GradioInfo"
      },
      "source": [
        "If you want to try different prompts many times, [Gradio](https://www.gradio.app/) is very easy to interact!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoTheRunGradio"
      },
      "source": [
        "#@title Do the Run!\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "def infer(\n",
        "        prompt,\n",
        "        init_image=None,\n",
        "        strength=0.75,\n",
        "        n_samples=4,\n",
        "        guidance_scale=7.5,\n",
        "        steps=50,\n",
        "        width=512,\n",
        "        height=512,\n",
        "        seed=\"random\",\n",
        "):\n",
        "    if seed == \"random\":\n",
        "        generator = None\n",
        "    else:\n",
        "        generator = torch.Generator(device=device).manual_seed(int(seed))\n",
        "    init_image = init_image.convert(\"RGB\").resize((width, height))\n",
        "    with autocast(device):\n",
        "        images = pipe(\n",
        "            prompt=[prompt] * n_samples,\n",
        "            init_image=init_image,\n",
        "            strength=strength,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_inference_steps=steps,\n",
        "            generator=generator\n",
        "        )[\"sample\"]\n",
        "    return images\n",
        "\n",
        "\n",
        "block = gr.Blocks(css=\".container { max-width: 800px; margin: auto; }\")\n",
        "\n",
        "with block as demo:\n",
        "    gr.Markdown(\"<h1><center>Japanese Stable Diffusion</center></h1>\")\n",
        "    gr.Markdown(\n",
        "        \"Japanese Stable Diffusion is a Japanese-specific latent text-to-image diffusion model capable of generating photo-realistic images given any text input.\"\n",
        "    )\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(mobile_collapse=False, equal_height=True):\n",
        "                text = gr.Textbox(\n",
        "                    label=\"Enter your prompt\", show_label=False, max_lines=1\n",
        "                ).style(\n",
        "                    border=(True, False, True, True),\n",
        "                    rounded=(True, False, False, True),\n",
        "                    container=False,\n",
        "                )\n",
        "                btn = gr.Button(\"Run\").style(\n",
        "                    margin=False,\n",
        "                    rounded=(False, True, True, False),\n",
        "                )\n",
        "\n",
        "        # input\n",
        "        strength_slider = gr.Slider(\n",
        "            label=\"Strength\",\n",
        "            maximum=1,\n",
        "            value=0.75\n",
        "        )\n",
        "        image = gr.Image(\n",
        "            label=\"Intial Image\",\n",
        "            type=\"pil\"\n",
        "        )\n",
        "        n_samples = gr.Number(value=4, label=\"n_samples\")\n",
        "        scale = gr.Number(value=7.5, label=\"cfg_scale\")\n",
        "        steps = gr.Number(value=50, label=\"steps\")\n",
        "        width = gr.Slider(minimum=64, maximum=2048, value=512, label=\"width\", step=64)\n",
        "        height = gr.Slider(minimum=64, maximum=2048, value=512, label=\"height\", step=64)\n",
        "        seed = gr.Textbox(value='random',\n",
        "                                  placeholder=\"If you fix seed, you get same outputs all the time. You can set as integer like 42.\",\n",
        "                                  label=\"seed\")\n",
        "\n",
        "        gallery = gr.Gallery(label=\"Generated images\", show_label=False).style(height=\"auto\")\n",
        "        text.submit(infer, inputs=[text, image, strength_slider, n_samples, scale, steps, width, height, seed], outputs=gallery)\n",
        "        btn.click(infer, inputs=[text, image, strength_slider, n_samples, scale, steps, width, height, seed], outputs=gallery)\n",
        "\n",
        "gr.Markdown(\n",
        "        \"\"\"___\n",
        "   <p style='text-align: center'>\n",
        "   Created by https://huggingface.co/hakurei\n",
        "   <br/>\n",
        "   </p>\"\"\"\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LicenseTop",
        "InstallTop"
      ],
      "machine_shape": "hm",
      "name": "Text2Image pipeline for Japanese Stabel Diffusion",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}